## From Douglas Bates Mixed-Effects in S

require(nlme)
require(lme4)
head(Rail)

## The model is yij = β + bi + epsilon ij
## bi∼N(0,σ2b), epsilonij∼N(0,σ2).
## σ2b is between rail variability, and σ2 within rail variability.

## Compare it to a simpler model without the classification factor when modeling group data
## corresponding to yij = β + epsilon ij:

fm1Rail.lm <- lm( travel ~ 1, data = Rail )
summary(fm1Rail.lm)

## The intercept is the mean of all the rails.

## The residual standard error of the first model is identical to the standard deviation:

sd(Rail$travel)

## Using a fixed-effect model for the classification or groups we get a
## yij = βi + ij formulation, where every rail has its mean:

fm2Rail.lm <- lm( travel ~ Rail - 1, data = Rail )
summary(fm2Rail.lm)

## Notice that the residual standard error in the last paragraph is 4, which is
## six times less than in the prior model, 23.65.

## This model accounts for the groups, BUT it only models the specific sample of rails
## used in the experiment, AND doesn't estimate the varibility BETWEEN rails. Further
## the number of parameters in the model increases linearly with the number of rails.

## The random effect models considers the rail effect to be randomly distributed around
## the population mean.
## The model is yij = β + bi + ij ,
## where β is the mean travel time across the population of rails being sam-
## pled, bi is a random variable representing the deviation from the population
## mean of the mean travel time for the ith rail,
## bi∼N(0,σ2b), epsilonij∼N(0,σ2).
## σ2b is BETWEEN rail variability, and σ2 within rail variability.


fm1Rail.lme <- lme(travel ~ 1, data = Rail, random = ~ 1 | Rail)
fm1Rail.lmeML <- update( fm1Rail.lme, method = "ML" )

fm1Rail.lme
fm1Rail.lmeML

## One of the outputs would be:
## (Intercept) 
##       66.5 

## Random effects:
## Formula: ~1 | Rail
##        (Intercept) Residual
## StdDev:    24.80547 4.020779

## The intercept of the stanDev of the random effects is close to the sd of the data.
sd(Rail$travel) # [1] 23.64505

## But not quite, because it is the variation between groups, not the sd of the entire dataset.
## Notice that the residual standard error are the same in the three last models: 4.021

head(ergoStool)
plot.design( ergoStool )  
## Clearly different stools require more or less effort, and so do subjects.
fm1Stool <-   lme(effort ~ Type, data = ergoStool, random=~1|Subject)
summary( fm1Stool )

## Notice that the intercept is the same as

mean(ergoStool[ergoStool$Type=='T1','effort'])

## and that...

mean(ergoStool[ergoStool$Type=='T2','effort'])-mean(ergoStool[ergoStool$Type=='T1','effort'])

## is the return for Fixed effects T2.

anova(fm1Stool)

#Interactions - replicated data

attach( Machines )  

head(Machines)

interaction.plot( Machine, Worker, score, las = 1)   


# If there were no interactions the lines would be parallel.

# This is the model without interactions:

fm1Machine <- lme( score ~ Machine, data = Machines, random=~1|Worker )
fm1Machine

# And this is the model with interactions:

fm2Machine <- update( fm1Machine, random=~1|Worker/Machine )
fm2Machine

anova( fm1Machine, fm2Machine )


# The lower AIC is for fm2Machine

# For unbalance data we can't fit interactions because of the lack of
# replication:

?ergoStool
head(ergoStool)
tail(ergoStool)

# Four "T" types of stool; and ning subjects each trying each stool
# only ONCE - three times for Machines

fm4Stool <- lme( effort ~ Type, ergoStool,~ 1 | Subject/Type )
intervals( fm4Stool )

# Why error? I don't know.
